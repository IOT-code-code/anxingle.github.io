---
layout: post
title: 台大机器学习基石笔记
category: 计算机
tags: 数学  机器学习
keywords: 
description: 
---

## 1. 机器学习是不可能的<br>
我们先来看一个简单的二分问题:<img src="http://www.forkosh.com/mathtex.cgi? \small if\hspace{0.2cm} \chi= \{0,1\}^3,y=\{0,\times \}"> can enumerate all candidate f as H?  

看似这个问题不难！输入一共可以有<img src="http://www.forkosh.com/mathtex.cgi? \small 2^3=8">种，那么hypothesis set大小就为<img src="http://www.forkosh.com/mathtex.cgi? \small 2^8=256">了。现在给出训练样本集（in-sample），    

<img src="http://xiangce.baidu.com/picture/detail/c0692111be2f8bcf2ef0d0d41f9527f2bd78b257">

我们选择一个机器学习算法从Hypothesis set中选出一个g,( <img src="http://www.forkosh.com/mathtex.cgi? \small pick\hspace{0.1cm}g\epsilon H,with \hspace{0.1cm}all\hspace{0.1cm} g(x_n)=y_n(like\hspace{0.1cm} PLA\hspace{0.2cm}algorithm).\hspace{0.2cm} \underline{Does\hspace{0.2cm} g\approx f?}">  )    

我们当然可以像感知机（PLA）那样，能够找出一个或者若干个好的g,在训练样本集（in-sample）上把所有的样本分对。上例中，
<center>No Free Lunch</center>     

<img src="http://xiangce.baidu.com/picture/detail/4a4720ed9c9a7d2b69a64b22d62f0a83d3becc3c" >    

我们可以在5个已经给出的输入上面得到g的预测是否正确，但是在未看过的三个输入上呢？我们会发现其实还有8种可能的选择。所以      

* g<img src="http://www.forkosh.com/mathtex.cgi? \small \approx"> f  inside D:sure!
* g<img src="http://www.forkosh.com/mathtex.cgi? \small \approx"> f  inside D:NO!but that's really what we want!   
 

## 2.机器学习怎么样是可能的（限制条件）
<img src="http://www.forkosh.com/mathtex.cgi? \Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}">



### Growth Function    
释义[^1] 
| 假设函数形式 | growth function | break points|
| -----|:----:|  ----:|
| positive rays   |N+1    | 2
| positive intervals|(1/2)N^2+(1/2)N+1 |  3
| 2D perceptrons| <2^N |4
| convex sets| 2^N |  no break|   

### break points[^2] 
### bounding function B(N,K)[^3]

[^1]:假设空间在N个样本点上能产生的最大二分（dichotomy）数量，其中二分是样本点在二元分类情况下的排列组合
[^2]: 第一个露出一线希望的点，在这个点后都会是break points。通俗解释：不能满足完全分类情形的样本点个数，完全二分类情形（shattered）是可分出  种二分类（dichotomy）的情形。

[^3]: maximum possible growth function，when break point=k